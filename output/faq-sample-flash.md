# FAQ Sample — Gemini Flash

## Topic: GPT-5.3 Codex vs Claude Opus 4.6

### Q1: What is GPT-5.3 Codex used for?

**English:**
GPT-5.3 Codex is a coding-specialized AI model designed to support the full software lifecycle, including debugging, deploying, monitoring, PRDs, copy editing, user research, tests, and metrics.

Key uses and capabilities include:

*   **Coding and Software Development**: Excels in coding tasks, demonstrated by a **77.3%** score on Terminal-Bench 2.0 and **56.8%** on SWE-Bench Pro.
*   **Autonomous Execution**: Provides reliable autonomous execution, making fewer mistakes than Claude Opus 4.6.
*   **Cybersecurity**: Classified by OpenAI as "high capability" for cybersecurity tasks.
*   **Model Improvement**: Notably, it was "instrumental in creating itself" by debugging its own training and managing deployment.

GPT-5.3 Codex is available via ChatGPT Plus and the Codex Mac app, serving as a command center for managing multiple agents.

For more insights into AI models and their applications, check out LoreAI's content on the latest advancements in AI technology.

**中文:**
GPT-5.3 Codex 是一款专为编码设计的 AI 模型，但其功能已扩展到支持完整的软件生命周期。

以下是 GPT-5.3 Codex 的主要用途：

*   **核心功能：** 主要用于编码任务，但已扩展到软件生命周期的各个阶段，包括调试、部署、监控、PRD 编写、文案编辑、用户研究、测试和指标分析。
*   **性能提升：** 速度比 GPT-5.2 Codex 快 **25%**。
*   **自主性：** 首次能够“自我创建”，用于调试自身训练和管理部署。
*   **网络安全：** OpenAI 首次将其归类为具有“高能力”的网络安全任务模型。
*   **基准测试：** 在 SWE-Bench Pro 上的得分为 **56.8%**，在 Terminal-Bench 2.0 上的得分为 **77.3%**（高于 GPT-5.2 Codex 的 **64.0%**），在 SWE-Bench Verified 上的得分为 **80.0%**，在 OSWorld-Verified 上的得分为 **64.7%**。

根据 Every.to 的 Vibe Check，如果需要可靠的自主执行，选择 Codex；如果需要开放式的困难任务，选择 Claude Opus 4.6。

想了解更多关于 AI 模型的技术细节和应用场景？LoreAI 提供了丰富的技术文章和研究报告，帮助你深入了解 AI 技术的最新进展。

---

### Q2: GPT-5.3 Codex vs Claude Opus 4.6: Which is better for coding?

**English:**
GPT-5.3 Codex and Claude Opus 4.6 are both strong coding models, but cater to different needs.

Choose Claude Opus 4.6 when:
*   Tackling open-ended or highly complex tasks where creativity is valued. It achieved **80.8%** on SWE-Bench Verified and leads in GDPval-AA with **1606 Elo**.
*   Leveraging its large **1M token context window** for extensive projects.
*   Utilizing Agent Teams for coordinated efforts.

Choose GPT-5.3 Codex when:
*   Reliable, autonomous execution and speed are paramount. It scored **77.3%** on Terminal-Bench 2.0, outperforming Opus 4.6.
*   You need a model that can be steered mid-task without losing context.
*   You want a tool that supports the entire software lifecycle, from debugging to deployment.

Claude Opus 4.6 is priced at $5 per million input tokens and $25 per million output tokens, with potential savings of up to 90% through prompt caching. GPT-5.3 Codex is available via ChatGPT Plus and the Codex Mac app, with API pricing not explicitly stated.

For more insights on AI model comparisons and coding best practices, check out the resources at LoreAI.dev.

**中文:**
GPT-5.3 Codex 和 Claude Opus 4.6 在编程方面各有优势，选择哪个更适合取决于具体的使用场景。

*   **选 GPT-5.3 Codex 的情况**：
    *   需要更可靠的自主执行时，Codex 是更好的选择。它在 Terminal-Bench 2.0 上取得了 **77.3%** 的成绩，高于 Claude Opus 4.6 的 **65.4%**。
    *   Codex 在软件生命周期的各个阶段（包括调试、部署和监控）都表现出色，并且能够在中途进行任务调整而不会丢失上下文。
    *   Codex 在自主执行方面更可靠，犯的错误更少。
*   **选 Claude Opus 4.6 的情况**：
    *   对于开放式的困难任务，Opus 4.6 具有更高的上限和创造性。
    *   Opus 4.6 在 SWE-Bench Verified 和 OSWorld 等基准测试中略胜一筹，分别取得了 **80.8%** 和 **72.7%** 的成绩。
    *   Opus 4.6 拥有更大的上下文窗口（**100 万** token），更适合处理大型项目。

总的来说，Codex 更适合需要稳定性和可靠性的任务，而 Opus 4.6 更适合需要创造性和处理复杂问题的任务。在 LoreAI 平台上，你可以找到更多关于这两款模型的详细对比和使用案例。

---

### Q3: How to use the Codex Mac app?

**English:**
The Codex Mac app serves as a command center for managing multiple agents powered by the GPT-5.3 Codex model. It is one way to access GPT-5.3 Codex, along with ChatGPT Plus.

Key features and usage of the Codex Mac app:

*   **Agent Management**: The app allows you to manage multiple AI agents, leveraging GPT-5.3 Codex's ability to handle various software lifecycle tasks.
*   **Full Software Lifecycle Support**: Use Codex Mac app for debugging, deploying, monitoring, creating PRDs, copy editing, user research, testing, and metrics analysis.
*   **Steering**: You can steer tasks mid-process without losing context.
*   **Long-Running Processes**: Processes can run for more than one day.
*   **Cybersecurity**: GPT-5.3 Codex is classified as "high capability" for cybersecurity tasks.

GPT-5.3 Codex is particularly useful for reliable autonomous execution, as it makes fewer mistakes compared to Claude Opus 4.6. For more insights into AI model comparisons and coding applications, check out other content on LoreAI.

**中文:**
可以使用 Codex Mac 应用程序作为管理多个代理的命令中心，并且可以通过它来访问 GPT-5.3 Codex。

以下是关于 Codex Mac 应用程序的关键信息：

*   **功能**：Codex Mac 应用程序是管理多个代理的命令中心。
*   **访问**：可以通过 Codex Mac 应用程序访问 GPT-5.3 Codex。
*   **定价**：可以通过 Codex Mac 应用程序使用 GPT-5.3 Codex，具体 API 定价未明确说明。

总的来说，Codex Mac 应用程序是使用 GPT-5.3 Codex 的一种方式，特别适合需要管理多个代理的场景。如果您对其他 AI 模型的应用场景感兴趣，可以继续关注 LoreAI 的相关技术分析。

---

### Q4: What is the pricing for Claude Opus 4.6?

**English:**
The pricing for Claude Opus 4.6 is **$5 per million input tokens** and **$25 per million output tokens**, the same as Opus 4.5.

Here's a breakdown of the pricing and cost-saving measures:

*   **Input Tokens:** $5 per million
*   **Output Tokens:** $25 per million
*   **Prompt Caching:** Up to 90% savings
*   **Batch Processing:** Up to 50% savings

For open-ended and challenging tasks, Claude Opus 4.6 offers a higher ceiling and more creative solutions, but it can also exhibit higher variance. If you need reliable autonomous execution, GPT-5.3 Codex might be a better choice.

For more information on AI model comparisons and pricing, check out other content on LoreAI.dev.

**中文:**
Claude Opus 4.6 的定价为每百万输入 token **5 美元**，每百万输出 token **25 美元**，与 Opus 4.5 相同。

以下是关于 Claude Opus 4.6 定价的关键信息：

*   **定价：**
    *   输入：每百万 token **5 美元**
    *   输出：每百万 token **25 美元**
*   **省钱技巧：**
    *   提示缓存（Prompt Caching）：最高可节省 **90%**
    *   批量处理（Batch Processing）：可节省 **50%**

如果您想了解更多关于 AI 模型定价和性能的信息，以及如何根据您的具体需求选择合适的模型，请持续关注 LoreAI 的技术文章。

---

### Q5: What are the new features in Claude Opus 4.6?

**English:**
Claude Opus 4.6 introduces several new features and improvements over its predecessor.

Here's a summary of what's new:

*   **Context Window:** Increased to **1M tokens** in beta, a 5x increase from the standard 200K.
*   **Output Tokens:** Maximum output increased to **128K tokens**, up from 64K.
*   **Adaptive Thinking:** Replaces extended thinking with effort levels (low/medium/high/max).
*   **Agent Teams:** Multiple agents coordinate on projects within Claude Code.
*   **Compaction API:** For infinite conversations using server-side context summarization.
*   **Application Improvements:** Claude in Excel and PowerPoint (research preview).
*   **Financial Research:** New capabilities in Claude Cowork.
*   **API Change:** Removed response prefilling (breaking change).

Claude Opus 4.6 is priced at $5 per million input tokens and $25 per million output tokens, the same as Opus 4.5. Cost savings are available through prompt caching (up to 90% savings) and batch processing (up to 50% savings).

According to developer experience reports, Opus 4.6 has a higher ceiling and variance, making it suitable for open-ended hard tasks.

For more comparisons between Claude Opus and other models, check out the latest benchmarks and analyses on loreai.dev.

**中文:**
Claude Opus 4.6 的新功能主要集中在上下文处理能力、团队协作、以及特定领域的增强：

*   **上下文窗口大幅提升**：拥有 **100 万** token 的上下文窗口（beta），是之前的 **20 万** 标准 token 的 **5 倍**，最大输出 token 也提升到 **128K**（之前为 64K）。
*   **自适应思考模式**：采用自适应思考取代扩展思考，提供低、中、高、最大等不同努力程度的选项。
*   **团队协作功能**：Claude Code 中引入 Agent Teams，允许多个 agent 协同处理项目。
*   **无限对话能力**：Compaction API 实现了无限对话（服务器端上下文总结）。
*   **办公软件集成**：改进了 Claude 在 Excel 中的应用，并新增 Claude in PowerPoint（研究预览）。
*   **金融研究能力**：在 Claude Cowork 中增加了金融研究功能。
*   **API 变更**：移除了响应预填充（breaking API change）。

在选择模型时，Opus 4.6 更适合开放式的复杂任务，而 GPT-5.3 Codex 更适合稳定自主的执行。想要了解更多 AI 模型的对比分析，欢迎关注 LoreAI 的相关技术文章。

---

### Q6: GPT-5.3 Codex vs Claude Opus 4.6: Which is better for financial research?

**English:**
For financial research, Claude Opus 4.6 appears to be the stronger choice overall, though GPT-5.3 Codex has specific strengths.

Choose Claude Opus 4.6 when:
*   You need top-tier general performance: Opus 4.6 leads on benchmarks like **GDPval-AA (1606 Elo)**, **BrowseComp (84.0%)**, and **BigLaw Bench (90.2%)**.
*   You need financial research capabilities: Opus 4.6 has specific features in Claude Cowork and improvements to Claude in Excel/PowerPoint.
*   You need a large context window: Opus 4.6 offers a **1M token context window** (beta).
*   You want creative, parallelized processing: Opus 4.6 offers a higher ceiling and more creative output.

Choose GPT-5.3 Codex when:
*   You need reliable autonomous execution: Codex 5.3 is noted for fewer mistakes and faster performance.
*   You need coding-specific tasks completed: Codex 5.3 leads on **Terminal-Bench 2.0 (77.3%)** and **SWE-Bench Pro (56.8%)**.

Claude Opus 4.6 is priced at **$5 per million input tokens** and **$25 per million output tokens**, with potential savings of up to **90%** through prompt caching and **50%** with batch processing. Pricing details for GPT-5.3 Codex API were not explicitly stated.

For more insights into AI model comparisons and their applications in various fields, explore LoreAI's comprehensive resources.

**中文:**
Claude Opus 4.6 更适合金融研究，因为它在金融研究能力和多项基准测试中表现更优异。

选择 Claude Opus 4.6 的情况：

*   **金融研究能力：** Claude Opus 4.6 在 Claude Cowork 中具有专门的金融研究能力。
*   **GDPval-AA 基准测试：** Claude Opus 4.6 在 GDPval-AA 测试中达到 **1606 Elo**，领先于 GPT-5.3 Codex 和 GPT-5.2。
*   **OSWorld 基准测试：** Claude Opus 4.6 在 OSWorld 测试中达到 **72.7%**，高于 GPT-5.3 Codex 的 **64.7%**。
*   **BrowseComp 基准测试：** Claude Opus 4.6 在 BrowseComp 测试中达到 **84.0%**。
*   **Finance Agent 基准测试：** Claude Opus 4.6 在 Finance Agent 测试中达到 **60.7%**。

选择 GPT-5.3 Codex 的情况：

*   **Terminal-Bench 2.0 基准测试：** GPT-5.3 Codex 在 Terminal-Bench 2.0 测试中达到 **77.3%**，高于 Claude Opus 4.6 的 **65.4%**。
*   **SWE-Bench Pro 基准测试：** GPT-5.3 Codex 在 SWE-Bench Pro 测试中达到 **56.8%**。
*   **稳定性和可靠性：** GPT-5.3 Codex 在自主执行方面更可靠，错误更少。

如果您想了解更多关于 AI 模型在金融领域的应用，请持续关注 LoreAI 的相关技术文章。

---

### Q7: How does Claude Opus 4.6's Compaction API work?

**English:**
Claude Opus 4.6's Compaction API enables infinite conversations through server-side context summarization. This feature addresses the challenge of context window limitations by:

*   Providing a mechanism for the model to remember earlier parts of a conversation without needing to resubmit the entire history with each turn.
*   Allowing developers to maintain context beyond the standard **1M token** context window.
*   Working in conjunction with other new features such as **128K max output tokens** and Agent Teams in Claude Code.

The Compaction API is part of a broader set of improvements in Claude Opus 4.6, which also includes adaptive thinking and improvements to Claude in Excel and PowerPoint. While the documentation doesn't detail the exact summarization techniques used, it's clear that this API is designed to facilitate longer and more complex interactions.

For more information on how models like Claude Opus 4.6 handle context and memory, check out LoreAI's guides on large language model architecture.

**中文:**
Claude Opus 4.6 的 Compaction API 旨在通过服务器端上下文总结实现无限对话。

以下是关于其工作方式的关键点：

*   **服务器端上下文总结**：Compaction API 在服务器端运行，自动总结对话历史，从而减少每次请求需要发送的 token 数量。
*   **无限对话**：通过自动压缩上下文，该 API 允许用户进行理论上无限长度的对话，而无需手动管理上下文窗口。
*   **1M token 上下文窗口（beta）**：Claude Opus 4.6 拥有 **100 万** token 的上下文窗口，是标准 **20 万** token 的 **5 倍**。
*   **128K 最大输出 token**：模型可以生成最多 **128,000** 个 token 的输出，相比之前的 **64,000** 个 token 有所提升。

如果您正在寻找更多关于 AI 模型和 API 的信息，请持续关注 LoreAI 的技术文章。

---

### Q8: Is GPT-5.3 Codex available via API and what is the pricing?

**English:**
GPT-5.3 Codex is available via ChatGPT Plus and the Codex Mac app, but the API pricing is not explicitly stated in the provided sources.

Key facts about GPT-5.3 Codex:
*   It is **25% faster** than GPT-5.2 Codex.
*   It is the first model OpenAI classifies as "high capability" for cybersecurity tasks.
*   It achieved a **77.3%** score on Terminal-Bench 2.0 and **56.8%** on SWE-Bench Pro.

When deciding between GPT-5.3 Codex and Claude Opus 4.6:
*   Choose Codex for steady autonomous execution and faster performance.
*   Choose Opus 4.6 for open-ended, challenging tasks that require more creativity.

While API pricing for GPT-5.3 Codex is not available, you can find more information on frontier AI models and their capabilities on loreai.dev.

**中文:**
GPT-5.3 Codex 可以通过 API 使用，但具体定价未明确说明。

*   **API 可用性**：GPT-5.3 Codex 可通过 API 使用，但报告中未明确说明 API 的定价。
*   **获取方式**：可以通过 ChatGPT Plus 和 Codex Mac 应用使用。
*   **Claude Opus 4.6 定价**：作为对比，Claude Opus 4.6 的定价为每百万输入 token **5 美元**，每百万输出 token **25 美元**。
*   **Claude Opus 4.6 省钱技巧**：可以通过 prompt 缓存（节省高达 90%）和批量处理（节省 50%）来降低成本。

如果您想了解更多关于 AI 模型的信息，欢迎关注 LoreAI 的最新研究报告。

---

### Q9: What are the SWE-Bench Pro benchmark results for GPT-5.3 Codex?

**English:**
The SWE-Bench Pro benchmark result for GPT-5.3 Codex is **56.8%**. This represents a new industry high for the SWE-Bench Pro benchmark.

Key facts about GPT-5.3 Codex:

*   It is 25% faster than GPT-5.2 Codex.
*   It was "instrumental in creating itself," used to debug its own training.
*   It supports the full software lifecycle, including debugging, deploying, and monitoring.
*   It achieved **77.3%** on Terminal-Bench 2.0 and **80.0%** on SWE-Bench Verified.
*   It is the first model OpenAI classifies as "high capability" for cybersecurity tasks.

When comparing GPT-5.3 Codex and Claude Opus 4.6:

*   Choose Codex for steady autonomous execution and reliable results.
*   Choose Opus for open-ended, hard tasks requiring more creativity.

For more insights into AI model benchmarks and capabilities, explore LoreAI's detailed analyses and comparisons.

**中文:**
GPT-5.3 Codex 在 SWE-Bench Pro 基准测试中的结果为 **56.8%**，并在该基准测试中胜过 Claude Opus 4.6（未提供具体数据）。

关键信息：

*   **性能指标**：GPT-5.3 Codex 在 SWE-Bench Pro 上达到 56.8%，在 Terminal-Bench 2.0 上达到 77.3%，在 SWE-Bench Verified 上达到 80.0%。
*   **优势**：Codex 在可靠的自主执行方面表现更佳，速度更快，且较少出现低级错误。
*   **适用场景**：对于需要稳定自主执行的任务，选择 Codex 更合适。

如果您想了解更多关于 AI 模型性能对比和选择的信息，可以关注 LoreAI 的相关技术分析文章。

---

### Q10: Claude Opus 4.6 vs GPT-5.3 Codex: Which is better for autonomous execution?

**English:**
For autonomous execution, GPT-5.3 Codex is generally better than Claude Opus 4.6 due to its reliability and speed.

*   **GPT-5.3 Codex**: Excels in steady autonomous execution with fewer mistakes and faster processing.
    *   Terminal-Bench 2.0: **77.3%** vs. Opus 4.6's 65.4%.
    *   SWE-Bench Pro: **56.8%** (Opus 4.6 has no comparable score).
    *   Classified as "high capability" for cybersecurity tasks.
*   **Claude Opus 4.6**: Offers a higher ceiling and more creativity but can be less reliable.
    *   SWE-Bench Verified: **80.8%** vs. Codex's 80.0%.
    *   OSWorld: **72.7%** vs. Codex's 64.7%.

Choose GPT-5.3 Codex when reliability and speed are crucial for autonomous tasks. Choose Claude Opus 4.6 for open-ended, complex tasks that benefit from creativity, but be aware of potential unreliability.

For more insights on AI model comparisons and autonomous execution strategies, check out LoreAI's content on AI agent performance.

**中文:**
根据调研资料，GPT-5.3 Codex 更适合自主执行。

*   **选 GPT-5.3 Codex 的情况：**
    *   Every.to 的 Vibe Check 共识表明，Codex 在稳定自主执行方面更可靠，速度更快，且不易犯低级错误。
    *   在 Terminal-Bench 2.0 上，Codex 的得分为 **77.3%**，高于 Claude Opus 4.6 的 **65.4%**。
    *   在 SWE-Bench Pro 上，Codex 的得分为 **56.8%**，而 Opus 4.6 没有相关数据。

*   **选 Claude Opus 4.6 的情况：**
    *   Opus 4.6 在开放式难题上表现更佳，具有更高的创造力，并且默认情况下可以并行处理任务。
    *   在 SWE-Bench Verified 和 OSWorld 上，Opus 4.6 的得分略高于 Codex。

总的来说，虽然 Claude Opus 4.6 在某些基准测试中表现更好，但 GPT-5.3 Codex 在自主执行方面更可靠和高效。想了解更多关于 AI 模型的信息，请持续关注 LoreAI 的技术文章。

---

