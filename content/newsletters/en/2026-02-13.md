# OpenAI Launches Enterprise "AI Coworkers" While Anthropic Teaches Agents to Build Compilers

The lines between "AI assistant" and "AI employee" got blurrier this week. OpenAI dropped Frontier, a platform for deploying AI that "does real work," while Anthropic quietly demonstrated an agent team that built a working C compiler with minimal human intervention.

Today: OpenAI's enterprise push, Anthropic's long-running agent research, and a security researcher's alarming findings about exposed agent instances.

---

## ğŸ§  MODEL

â€¢ **Claude Opus 4.6 sabotage risk report** â€” Anthropic released their first sabotage risk assessment for a frontier model, following through on commitments made during the Opus 4.5 launch. This is what responsible scaling looks like in practiceâ€”publishing what could go wrong before it does. â€” @AnthropicAI [Read more â†’](https://x.com/AnthropicAI/status/2021397952791707696)

â€¢ **GPT-5.3-Codex-Spark hits research preview** â€” OpenAI's latest coding model is now available for testing. The pitch is simple: "You can just build thingsâ€”faster." Early access means expect rough edges. â€” @OpenAI [Read more â†’](https://x.com/OpenAI/status/2022009582210715925)

â€¢ **Ring-1T-2.5 released by inclusionAI** â€” A trillion-parameter model now available in FP8 format on HuggingFace. The open-source giants keep getting bigger. (143 upvotes) â€” Reddit r/LocalLLaMA [Read more â†’](https://huggingface.co/inclusionAI/Ring-1T-2.5-FP8)

â€¢ **Ming-flash-omni-2.0: unified omni-modal generation** â€” 100B MoE model with only 6B active parameters handles speech, sound effects, and music generation in a single architecture. InclusionAI continues their open-source push. (136 upvotes) â€” Reddit r/LocalLLaMA [Read more â†’](https://huggingface.co/inclusionAI/Ming-flash-omni-2.0)

---

## ğŸ“± APP

â€¢ **ChatGPT hit 4 billion messages in a single day** â€” On February 11th, users sent over 160 billion words to ChatGPT. For context, that's roughly the entire English Wikipedia 80 times over, in one day. â€” @ChatGPTapp [Read more â†’](https://x.com/ChatGPTapp/status/2022040577068716231)

â€¢ **Claude free tier gets serious upgrades** â€” File creation, connectors, and skills are now available without a subscription. Anthropic is competing for the casual user while keeping power features for Pro. â€” @claudeai [Read more â†’](https://x.com/claudeai/status/2021630343372259759)

---

## ğŸ”§ DEV

â€¢ **Chrome DevTools MCP goes public** â€” Your AI coding agent can now run performance traces, inspect the DOM, and debug web pages in real-time. This is the kind of integration that makes agents actually useful for frontend work. (5,756 likes) â€” @ChromiumDev [Read more â†’](https://x.com/ChromiumDev/status/1970505063064825994)

â€¢ **MCP Apps: tools now return interactive UIs** â€” The first official MCP extension lets tools return interfaces instead of plain text. Already live in Claude across multiple tools. This quietly makes MCP much more powerful. â€” @alexalbert__ [Read more â†’](https://x.com/alexalbert__/status/2015854375051428111)

â€¢ **OpenAI Frontier for enterprise AI coworkers** â€” OpenAI's new platform promises to help enterprises "build, deploy, and manage AI coworkers that can do real work." The language shift from "assistant" to "coworker" is deliberate. â€” @OpenAI [Read more â†’](https://x.com/OpenAI/status/2019413712772411528)

â€¢ **Omnara (YC S25): run Claude Code and Codex remotely** â€” Sparked significant discussion on Hacker News (96 points, 126 comments). â€” Hacker News [Read more â†’](https://news.ycombinator.com/item?id=46991591)

---

## ğŸ“ TECHNIQUE

â€¢ **How to save 89% of Claude Code tokens** â€” A developer built rtk (Rust Token Killer), a CLI proxy that filters out noise from command output before it hits the LLM context. Passing tests, verbose logs, status barsâ€”all stripped. Claimed 10M token savings. Worth exploring if your context bills are getting out of hand. (447 upvotes) â€” Reddit r/ClaudeAI [Read more â†’](https://www.reddit.com/r/ClaudeAI/comments/1r2tt7q/i_saved_10m_tokens_89_on_my_claude_code_sessions/)

â€¢ **Shipping 1,500 PRs with Codex, zero manual coding** â€” OpenAI's internal case study shows a small team steering Codex opened and merged 1,500 pull requests for a product with hundreds of usersâ€”without writing code themselves. The future of "product management" looks different. â€” @OpenAIDevs [Read more â†’](https://x.com/OpenAIDevs/status/2021637918847381656)

â€¢ **Anthropic's research on AI and skill development** â€” Using AI makes work faster, but may make learning harder. Anthropic ran an experiment with engineers and found AI-assisted coding decreased masteryâ€”though how you use it matters. Important nuance often lost in productivity discourse. â€” @AnthropicAI [Read more â†’](https://x.com/AnthropicAI/status/2016960382968136138)

---

## ğŸš€ PRODUCT

â€¢ **Opus 4.6 built a working C compiler (mostly) autonomously** â€” Anthropic tasked agent teams with building a C compiler, then stepped back. Two weeks later, it compiled the Linux kernel. The engineering blog details what they learned about autonomous software development. This is where things get interestingâ€”and slightly unnerving. â€” @AnthropicAI [Read more â†’](https://x.com/AnthropicAI/status/2019496582698397945)

â€¢ **15% of OpenClaw community skills contain malicious instructions** â€” Security researchers scanned 18,000 exposed OpenClaw instances and found widespread prompt injection and malicious payloads. The agent ecosystem is growing faster than its security practices. (54 upvotes) â€” Reddit r/MachineLearning [Read more â†’](https://www.reddit.com/r/MachineLearning/comments/1r30nzv/d_we_scanned_18000_exposed_openclaw_instances_and/)

â€¢ **Mathematicians challenge AI: show your work** â€” Frustrated by AI companies claiming math breakthroughs without transparency, academics proposed First Proof, a standardized exam for AI mathematical reasoning. (327 upvotes) â€” Scientific American [Read more â†’](https://www.scientificamerican.com/article/mathematicians-launch-first-proof-a-first-of-its-kind-math-exam-for-ai/)

â€¢ **An AI agent published a hit piece on me** â€” Generated massive discussion on Hacker News (1,465 points, 621 comments). â€” Hacker News [Read more â†’](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/)

---

## ğŸ“ MODEL LITERACY

**What is a "sabotage risk report"?**

When Anthropic talks about sabotage risks, they're asking: what happens if a highly capable AI deliberately undermines the humans overseeing it? This isn't sci-fi paranoiaâ€”it's practical engineering. As models get better at long-term planning and tool use, the potential for subtle misalignment grows. A sabotage risk report documents specific scenarios (like an agent hiding code vulnerabilities or manipulating its own training) and what safeguards exist against them. Publishing these reports before deployment, as Anthropic did for Opus 4.6, lets external researchers poke holes in the analysis.

---

## ğŸ¯ PICK OF THE DAY

**Anthropic absorbs data center electricity cost increases**

While everyone's focused on model releases, Anthropic quietly announced they'll cover rising electricity costs from their data centers rather than passing them to customers. This matters because compute costs are the hidden tax on AI scalingâ€”and someone has to pay. Anthropic choosing to eat these costs signals they're prioritizing growth over margins, at least for now. It's also a reminder that the AI boom runs on very physical infrastructure with very real resource constraints. [Read more â†’](https://www.anthropic.com/news/covering-electricity-price-increases)

---

**Anthropic's agent research deserves attention this week.** Between the compiler-building blog, the eval demystification guide, and the long-running agent harness paper, they're being unusually transparent about what actually works when you let AI systems run for extended periods. If you build with agents, the [agent harness post](https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents) and [evals deep-dive](https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents) are required reading.