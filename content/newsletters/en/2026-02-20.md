# Anthropic Drops Sonnet 4.6 as Claude's Engineering Team Goes Deep on Agent Infrastructure

Anthropic dominated this week with a new model release and a flurry of engineering deep-dives on building production agents. Meanwhile, OpenAI quietly shipped new image generation models and Google's CEO took the stage at the AI Impact Summit. Today: Claude Sonnet 4.6 benchmarks, advanced tool use patterns, and why your agentic coding evals might be lying to you.

---

## ğŸ§  MODEL

â€¢ **Claude Sonnet 4.6 launches** â€” Anthropic's latest mid-tier model reportedly gives Opus 4.6 serious competition on benchmarks. The cost-performance ratio continues to compress. â€” Anthropic Blog [Read more â†’](https://www.anthropic.com/news/claude-sonnet-4-6)

â€¢ **OpenAI ships new image generation models** â€” Latest models for image generation now available via API. â€” OpenAI Changelog (Feb 2026) [Read more â†’](https://developers.openai.com/api/docs/changelog)

---

## ğŸ”§ DEV

â€¢ **Advanced tool use hits Claude Developer Platform** â€” Three new beta features let Claude discover, learn, and execute tools dynamically at runtime. This is Anthropic's answer to static tool definitionsâ€”agents that can expand their own capabilities mid-conversation. â€” Anthropic Engineering [Read more â†’](https://www.anthropic.com/engineering/advanced-tool-use)

â€¢ **Claude Code 2.1.41 ships** â€” Notable update includes the tip that `!` prefix runs terminal commands directly inside Claude Code. â€” @adocomplete [Read more â†’](https://x.com/adocomplete/status/2022374013104984177)

â€¢ **Agent Skills: runtime capability injection** â€” Skills are folders of instructions, scripts, and resources that Claude can learn at runtime. Upload once, use in any request. The real power is adding custom skills. â€” @adocomplete [Read more â†’](https://x.com/adocomplete/status/2022444640650301602)

â€¢ **MCP Connector simplifies server connections** â€” Pass a server URL in your request, Claude handles discovery and tool calls. Supports multiple servers per request, allowlist/denylist, and OAuth. No client to build. â€” @adocomplete [Read more â†’](https://x.com/adocomplete/status/2022807974071411186)

â€¢ **Batch API: 50% cost reduction for async workloads** â€” Send up to 100K requests, results within 24 hours (usually under an hour). Same API shape, half the cost. Ideal for evals and data pipelines. â€” @adocomplete [Read more â†’](https://x.com/adocomplete/status/2023156611150389636)

---

## ğŸ“ TECHNIQUE

â€¢ **Effective harnesses for long-running agents** â€” Anthropic's engineering team studied how human engineers maintain context across sessions and built those patterns into agent harnesses. Key insight: the challenge isn't the model, it's the scaffolding. â€” Anthropic Engineering [Read more â†’](https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents)

â€¢ **Quantifying infrastructure noise in coding evals** â€” Infrastructure configuration can swing agentic coding benchmarks by several percentage pointsâ€”sometimes more than the gap between top models on leaderboards. Your eval results may say more about your setup than your model choice. â€” Anthropic Engineering [Read more â†’](https://www.anthropic.com/engineering/infrastructure-noise)

â€¢ **Demystifying evals for AI agents** â€” The capabilities that make agents useful also make them hard to evaluate. Effective strategies combine multiple techniques to match system complexity. â€” Anthropic Engineering [Read more â†’](https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents)

â€¢ **Designing AI-resistant technical evaluations** â€” What Anthropic learned from three iterations of a performance engineering take-home that Claude keeps beating. Useful if you're building hiring assessments. â€” Anthropic Engineering [Read more â†’](https://www.anthropic.com/engineering/AI-resistant-technical-evaluations)

---

## ğŸš€ PRODUCT

â€¢ **Anthropic + Infosys partner on telecom AI agents** â€” Joint effort to build AI agents for telecommunications and regulated industries. Enterprise deals accelerating. â€” Anthropic Blog [Read more â†’](https://www.anthropic.com/news/anthropic-infosys)

â€¢ **Anthropic signs MOU with Rwanda** â€” Partnership focused on AI deployment in health and education sectors. â€” Anthropic Blog [Read more â†’](https://www.anthropic.com/news/anthropic-rwanda-mou)

â€¢ **Sundar Pichai at AI Impact Summit 2026** â€” "No technology has me dreaming bigger than AI." Google's CEO delivered opening remarks at the summit. â€” Google AI Blog [Read more â†’](https://blog.google/company-news/inside-google/message-ceo/sundar-pichai-ai-impact-summit-2026/)

---

## ğŸ“ MODEL LITERACY

**What is "infrastructure noise" in benchmarks?** When you run an AI coding benchmark, the results depend on more than just the model. Container configuration, filesystem speed, network latency, and timeout settings all affect scores. Anthropic found these environmental factors can shift results by several percentage pointsâ€”sometimes larger than the actual performance gap between competing models. This means leaderboard rankings may reflect infrastructure choices as much as model capability.

---

## ğŸ¯ PICK OF THE DAY

**Advanced tool use on Claude Developer Platform** â€” This is the most significant developer-facing feature this week. Instead of hardcoding every tool Claude can use, you can now let it discover and learn tools dynamically. For anyone building agents that need to adapt to new APIs or expand capabilities without redeployment, this changes the architecture. [Read more â†’](https://www.anthropic.com/engineering/advanced-tool-use)