# Anthropic's Take-Home Test Falls to Its Own AI While OpenAI Embraces Ads

Anthropic's performance engineering candidates used to face a notoriously difficult take-home exam. Then Opus 4.5 beat it. Meanwhile, OpenAI is explaining its new ad strategy on a podcastâ€”because nothing says "AI for humanity" quite like monetization.

Today: Opus outsmarts its creators, Cline CLI goes parallel, and a $10 RISC-V board runs a full AI assistant.

---

## ğŸ§  MODEL

â€¢ **Opus 4.5 defeats Anthropic's own hiring test** â€” The irony is delicious: Anthropic designed a notoriously difficult take-home exam for performance engineering candidates, and their flagship model just beat it. They've now had to redesign the test. When your AI is too good for your own interview process, that's either a flex or a problem. â€” @AnthropicAI [Read more â†’](https://x.com/AnthropicAI/status/2014143403144200234)

â€¢ **TranslateGemma brings open translation to 55 languages** â€” Google DeepMind dropped a new family of translation models in 4B, 12B, and 27B sizes. The focus is efficiency over raw sizeâ€”useful for teams who need multilingual support without burning through compute budgets. â€” @GoogleDeepMind [Read more â†’](https://x.com/GoogleDeepMind/status/2011848249850630363)

â€¢ **Heretic 1.2 cuts VRAM 70% for model "derestriction"** â€” The controversial uncensoring tool now supports quantization and vision-language models. Over 1,300 models on HuggingFace have been processed with it. Make of that what you will. (270 upvotes) â€” Reddit r/LocalLLaMA [Read more â†’](https://www.reddit.com/r/LocalLLaMA/comments/1r4n3as/heretic_12_released_70_lower_vram_usage_with/)

â€¢ **Nemotron 3 Super/Ultra coming H1 2026 with FP4 pre-training** â€” NVIDIA's VP of Applied Deep Learning dropped hints in an interview. FP4 pre-training is the interesting bitâ€”could mean significantly smaller model files with comparable performance. â€” Reddit r/LocalLLaMA (59 upvotes) [Read more â†’](https://www.reddit.com/r/LocalLLaMA/comments/1r4lx7x/nemotron3_superultra_fp4_pretraining_h1_2026/)

---

## ğŸ“± APP

â€¢ **OpenAI explains its ad strategy** â€” If you've been wondering how OpenAI plans to make ChatGPT Free and Go tiers sustainable, the answer is ads. Their podcast this week features the ads team lead explaining the principles behind it. "Expanding AI access for all" is the framing; recurring revenue is the reality. â€” @OpenAI [Read more â†’](https://x.com/OpenAI/status/2021025290366091442)

â€¢ **Pentagon used Claude during Maduro raid, Anthropic not happy** â€” This sparked discussion on Reddit (241 upvotes) about the tensions between AI companies and government use of their tools. The full story is worth reading for the policy implications. â€” Reddit r/artificial [Read more â†’](https://www.axios.com/2026/02/13/anthropic-claude-maduro-raid-pentagon)

â€¢ **Magnus Carlsen crushed ChatGPT without losing a single piece** â€” The world chess champion demonstrated that human intuition still has an edge in positional play. ChatGPT's calculation abilities couldn't compensate for Carlsen's long-term strategic understanding. (2,390 likes) â€” @IntEngineering [Read more â†’](https://x.com/IntEngineering/status/2022400491561320929)

---

## ğŸ”§ DEV

â€¢ **Cline CLI 2.0: parallel agents, headless CI/CD, completely redesigned** â€” This is a substantial release. You get parallel agents running in terminal, ACP support for any editor, and Minimax M2.5 plus Kimi K2.5 are free for a limited time. If you're building AI-assisted pipelines, worth checking out. (2,213 likes) â€” @cline [Read more â†’](https://x.com/cline/status/2022341254965772367)

â€¢ **MCP Connector: connect to MCP servers without building a client** â€” Pass a server URL in your API request, Claude handles discovery and tool calls. Multiple servers per request, OAuth support, tool allowlisting. This removes a lot of boilerplate for MCP integrations. â€” @adocomplete [Read more â†’](https://x.com/adocomplete/status/2022807974071411186)

â€¢ **28 official Claude Code plugins you probably didn't know existed** â€” Someone discovered a hidden plugin marketplace at `~/.claude/plugins/marketplaces/claude-plugins-official/plugins/` with 28 plugins. Most aren't documented anywhere obvious. (374 upvotes) â€” Reddit r/ClaudeAI [Read more â†’](https://www.reddit.com/r/ClaudeAI/comments/1r4tk3u/there_are_28_official_claude_code_plugins_most/)

â€¢ **agtx: Kanban-style autonomous coding in terminal** â€” A new tool that isolates AI coding tasks with git worktrees and tmux sessions. Tasks flow through Backlog â†’ Planning â†’ Running â†’ Review â†’ Done. Nice workflow if you're running multiple parallel coding agents. (113 upvotes) â€” Reddit r/ClaudeAI [Read more â†’](https://www.reddit.com/r/ClaudeAI/comments/1r4hb37/autonomous_multisession_ai_coding_in_the_terminal/)

---

## ğŸ“ TECHNIQUE

â€¢ **Guide to software engineering with LLMs** â€” A comprehensive guide that's been making the rounds. (1,233 likes) â€” @tom_doerr [Read more â†’](https://x.com/tom_doerr/status/2021995079057973530)

â€¢ **get-shit-done: meta-prompting system for Claude Code** â€” A spec-driven development system that's trending on GitHub. Lightweight context engineering for Claude Code and OpenCode users. â€” GitHub Trending [Read more â†’](https://github.com/gsd-build/get-shit-done)

â€¢ **FastCode: accelerating code understanding** â€” New tool from HKUDS for faster codebase comprehension. â€” GitHub Trending [Read more â†’](https://github.com/HKUDS/FastCode)

---

## ğŸš€ PRODUCT

â€¢ **PicoClaw: full AI assistant on $10 RISC-V hardware** â€” This is wild. Someone matched OpenClaw's core features with 1% of the code and 1% of the memory. Runs on 10MB RAM. If it runs Linux, it can now be a personal AI agent. The embedded AI future is arriving faster than expected. (5,039 likes) â€” @SipeedIO [Read more â†’](https://x.com/SipeedIO/status/2020832292885930288)

â€¢ **KaniTTS2: open-source voice cloning in 3GB VRAM** â€” A 400M parameter TTS model designed for real-time conversational use. English and Spanish support, with more languages coming. Pretrain code included if you want to fine-tune. (175 upvotes) â€” Reddit r/LocalLLaMA [Read more â†’](https://www.reddit.com/r/LocalLLaMA/comments/1r4sivv/kanitts2_opensource_400m_tts_model_with_voice/)

â€¢ **Velo: desktop email client built 100% with Claude** â€” Open-source, local-first, keyboard-driven. Built with Tauri, React, and Rust. The interesting part isn't the email client itselfâ€”it's that someone shipped a complete desktop app using only AI assistance. (162 upvotes) â€” Reddit r/ClaudeAI [Read more â†’](https://www.reddit.com/r/ClaudeAI/comments/1r4f8bw/i_built_a_full_desktop_email_client_100_coded/)

â€¢ **Perch 2.0 extends bioacoustics AI to underwater** â€” Google DeepMind's foundation model was trained on terrestrial animals, but the new version works surprisingly well for marine ecosystems. Useful for conservation researchers. â€” @GoogleDeepMind [Read more â†’](https://x.com/GoogleDeepMind/status/2020933684535361840)

---

## ğŸ“ MODEL LITERACY

**What is FP4 quantization?** Models are typically trained and stored in FP16 (16-bit floating point) or FP32 (32-bit). FP4 means compressing the model to just 4-bit precisionâ€”each weight takes up 4x less memory than FP16. The tradeoff is accuracy loss, but modern quantization techniques have gotten remarkably good at preserving model quality. When NVIDIA mentions FP4 *pre-training* for Nemotron 3, that's unusualâ€”most quantization happens after training. If they've cracked FP4 pre-training, it could mean training larger models on smaller hardware.

---

## ğŸ¯ PICK OF THE DAY

**Smart sleep mask broadcasts brainwaves to open MQTT broker** â€” A Kickstarter backer reverse-engineered their smart sleep mask and discovered it sends users' brainwave data to an unprotected MQTT brokerâ€”and accepts commands to send electrical impulses back. This isn't an AI story per se, but it's a perfect case study in why IoT + AI devices need security audits before they touch your brain. (289 points, 135 comments on HN) [Read more â†’](https://aimilios.bearblog.dev/reverse-engineering-sleep-mask/)

---

**Industry note:** IBM is tripling entry-level hiring after finding limits to AI adoption (110 points on HN). Meanwhile, Microsoft's AI chief Mustafa Suleyman gives white-collar automation 18 months. The disconnect between "AI will replace everyone" and "we need more humans" continues.