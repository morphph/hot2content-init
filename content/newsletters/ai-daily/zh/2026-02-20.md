# Gemini 3.1 Pro 推理跑分翻倍，Kimi K2.5 下载量突破百万

**2026 年 2 月 20 日**

Google DeepMind 放出 Gemini 3.1 Pro，ARC-AGI-2 得分 77.1%——比上一代翻了一倍多。与此同时，Moonshot 的 Kimi K2.5 在 HuggingFace 上突破百万下载，Anthropic 推出 Claude Code Security，网安股应声下跌。

---

## 🧠 模型 — 新发布 & 趋势

**Gemini 3.1 Pro 发布** — Google DeepMind 最新旗舰。ARC-AGI-2 得分 77.1%（较 3 Pro 翻倍以上）。推理能力重大升级。（@GoogleDeepMind、@GoogleAI — 6K+❤️）

**Kimi K2.5 持续大热** — Moonshot 的多模态模型在 HuggingFace 上突破 100 万+下载，2K❤️。本周下载量最高的模型。

**Qwen3.5-397B-A17B** — Qwen 的超大 MoE 新模型。768❤️，10.5 万下载。另有 Qwen3-Coder-Next（928❤️，39 万下载）用于编码任务。

**GLM-5（ZAI）** — 1,374❤️，17.4 万下载。另有 GLM-OCR 做图像转文本（1,092❤️，120 万下载——大规模采用）。

**MiniMax M2.5** — 806❤️，12.3 万下载，文本生成。

**TTS 大爆发** — 多个 TTS 模型上榜：Qwen3-TTS（1,108❤️，87.8 万下载）、MOSS-TTS、SoulX-Singer、kani-tts-2。

**Stability 的新开源 LLM** — 7B 参数，商用免费。（@SullyOmarr — 1.9K❤️）

## 📱 应用 — 消费端 & 产品动态

**Claude 进入 PowerPoint** — Pro 计划可用，支持连接器从日常工具中提取上下文。（@claudeai — 8.3K❤️）

**Claude Code Desktop 升级** — 可预览运行中的应用、审查代码、在后台处理 CI 失败和 PR。（@claudeai — 5.6K❤️）

**Claude Code → Figma** — 通过更新的 Figma MCP 服务器将构建成果直接推入 Figma。（@claudeai — 16.3K❤️ 热门）

**ChatGPT 代码块升级** — 更强交互性：在同一界面编写、编辑、预览代码，支持分屏视图。（@OpenAIDevs — 2K❤️）

**Gemini 可以创作音乐** — DeepMind 宣布的新能力。

## 🔧 开发 — 工具 & API

**Claude Code Security** — 研究预览版。扫描代码库漏洞，建议补丁。面向 Team 和 Enterprise。（@claudeai — 22.2K❤️，当日最热推文）

**自动 prompt 缓存** — Anthropic API 不再需要手动设置缓存断点！（@alexalbert__ — 1.4K❤️）

**GitHub 官方 MCP 服务器** — 开源，从 AI agent 自动化 GitHub 工作流。（@akshay_pachaar — 2.4K❤️）

**OpenAI Responses API 中的 Skills** — 新的"Skills"原语 + 支持容器网络的 Hosted Shell 工具。（2/10 changelog）

**GPT-5.2 / GPT-5.2-Codex 提速 40%** — 推理优化，模型不变。（2/3 changelog）

**AWS Multi-Agent AI 框架** — 跨专用 agent 动态路由 LLM 查询。（@Sumanth_077 — 2K❤️）

**GGML + llama.cpp 加入 HuggingFace** — 确保本地 AI 的长期发展。（HF 博客，2/20）

**Transformers.js v4 Preview** — 已上线 NPM。（HF 博客）

**DreamDojo（NVIDIA）** — 开源交互式世界模型，用于机器人模拟。（@DrJimFan — 489❤️）

## 📝 技巧 — 实践 & 洞察

**Prompt 缓存是一切的关键** — Thariq（Claude Code 负责人）分享了围绕缓存约束设计的深度经验：静态内容放前面、会话中不要换工具、用消息传递更新。（热门文章）

**评测中的基础设施噪声** — Anthropic 工程博客：配置可使 agent 编码 benchmark 波动数个百分点。（anthropic.com/engineering）

**测量 AI agent 自主性** — Anthropic 新研究，量化实践中的 agent 自主性。（2/18）

**Karpathy 谈定制化软件** — 自己做了个心肺训练追踪应用。"对即将到来的高度定制化软件时代非常感兴趣。"（10.4K❤️）

**levelsio：每个网站就是一个聊天** — 在每台 VPS 上跑 Claude Code，每个网站都是管理界面。（822❤️）

**并行 agent 的"精神崩溃"** — @simonw："丢了一整个功能——找不到分支、worktree 还是云实例了" 😅（1.1K❤️）

## 🚀 产品 — 新产品 & Agent

**LLM Engineer Toolkit** — 精选 120+ 开源 LLM 库，覆盖全栈。（@Sumanth_077 — 2.6K❤️）

**Ami — 最快的前端编码 agent** — 视频演示（非加速）。（@aidenybai — 2.5K❤️）

**MCP 服务器目录** — 一个网站收录了 2,617 个 MCP 服务器。（@karminski3 — 1.7K❤️）

**nvidia/personaplex-7b-v1** — 音频到音频模型，50.9 万下载。HF 热榜。

**DeepGen-1.0** — 新文生图模型。（124❤️）

**Capybara（xgen-universe）** — 全模态模型。（136❤️）

---

## 🎓 模型小课堂：Prompt 缓存

**是什么：** 当你向 LLM API 发送请求时，系统可以缓存请求的前缀部分。如果下一个请求以相同方式开头，就复用已缓存的计算，而不是从头处理。

**为什么重要：** 对于像 Claude Code 这样在一个会话中发送几十个 API 调用的 agent，每次调用都共享相同的系统提示 + 工具 + 对话历史。没有缓存，每次调用都要从头处理全部内容。有了缓存，只有新增部分按全价计费。

**关键洞察：** 这是前缀匹配——从头开始必须完全一致。系统提示改一个字？缓存失效。工具重排序？缓存失效。这就是为什么 Anthropic 刚推出了自动 prompt 缓存——你不用再操心缓存断点了。

---

## 🎯 今日之选：Claude Code Security

Anthropic 推出内建于 Claude Code 的安全扫描器，发现代码库中的漏洞并建议补丁供人工审查。这很重要因为：

1. **主动出击** — 无需你主动要求就扫描代码
2. **Agent 式** — 不只是标记问题，还会写修复补丁
3. **安全叙事** — 当 AI 写越来越多代码时，AI 也需要审计越来越多代码

以 22K 赞成为当日最热 AI 推文。目前为 Team 和 Enterprise 计划的研究预览版。值得关注，这可能成为代码库安全审计的默认方式。

🔗 https://x.com/claudeai/status/2024574133011673516
