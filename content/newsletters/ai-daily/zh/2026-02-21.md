# GGML 加入 Hugging Face，微软开源 1-bit LLM 推理框架

**2026 年 2 月 21 日**

本地 AI 生态迎来了最重要的一周。llama.cpp 的创造者——几乎所有本地大模型工具背后的引擎——正式加入 Hugging Face。与此同时，微软开源了 bitnet.cpp，让大模型在 CPU 上无需 GPU 即可高效运行。开源模型趋势榜则被 Qwen、NVIDIA、Moonshot 的发布霸占。

---

## 🧠 模型动态

**GGML & llama.cpp 加入 Hugging Face。** 最受欢迎的本地推理引擎的创造者加入 HF，确保本地 AI 的长期发展。对整个开源生态来说意义重大。[查看详情 →](https://huggingface.co/blog/ggml-joins-hf)

**Qwen3.5-397B-A17B。** 阿里新的巨型 MoE 模型（397B 参数，17B 活跃），829❤️。多模态（图文到文本）。[查看详情 →](https://huggingface.co/Qwen/Qwen3.5-397B-A17B)

**NVIDIA PersonaPlex-7B。** 音频到音频模型，HF 趋势第一（2,116❤️）。语音克隆/变换。

**MiniMax M2.5。** 新的文本生成模型（833❤️）。

**Kimi K2.5。** Moonshot AI 多模态模型（2,065❤️）。

**微软开源 1-bit LLM 推理。** bitnet.cpp 让大模型在 CPU 上无需 GPU 即可运行。X 上 16.7K❤️。

## 📱 产品应用

**Claude："广告要进 AI 了。但不会进 Claude。"** Anthropic 本周互动量最高的推文（51K❤️），直接对标 OpenAI 的 ChatGPT 广告测试。

**Google Gemini 可以作曲了。** DeepMind 宣布 Gemini 的新音乐生成能力。

**Project Genie。** Google 实验性的虚拟世界创建、编辑和探索原型。Karpathy 称之为"最令人难以置信的接近科幻起飞的东西"（35K❤️）。

## 🔧 开发工具

**Claude Code Security。** 限量研究预览版。扫描代码库漏洞并建议修复。46K❤️。

**Claude Code Desktop 升级。** 预览运行中的应用、代码审查、后台处理 CI 和 PR。23.8K❤️。

**OpenAI Skills + Hosted Shell。** Responses API 新增 Skills（本地/托管执行）和 Shell 工具（容器内网络）。

**Figma MCP 服务器更新。** 从 Claude Code 直接推设计到 Figma。16.5K❤️。

**Phantom MCP 服务器。** Agent 可以在 Phantom 支持的链上交换、签名、管理加密地址。5.5K❤️。

**AWS 多 Agent AI 框架。** 管理多个 AI Agent 和切换的新框架。2K❤️。

**AI Agent 写 CUDA Kernel。** HuggingFace 博客。

**Transformers.js v4 预览版。** 上线 NPM。

## 📝 技术洞察

**Karpathy 的 Claude 编码笔记。** 连续几周用 Claude 编码后的随机笔记。涵盖工作流和最佳实践。39.4K❤️。

**CLAUDE.md 最佳实践。** 整理 Claude Code 创作者所有关于编写高效 CLAUDE.md 文件的最佳实践。2.8K❤️。

**基础设施噪声影响编码评测。** Anthropic 工程博客：基础设施配置可以让基准测试波动数个百分点。[查看详情 →](https://www.anthropic.com/engineering/infrastructure-noise)

**Unsloth + HF Jobs。** 在 Hugging Face Jobs 上用 Unsloth 免费训练 AI 模型。

## 🚀 前沿探索

**Rork Max。** 一键生成 iPhone、Watch、iPad、TV、Vision Pro 应用的 AI。"甚至能做 Pokémon Go。" 17.6K❤️。

**Peter Steinberger 加入 OpenAI。** 推动下一代个人 Agent。Sam Altman 亲自宣布，46.5K❤️。

**Anthropic 用并行 Claude 造 C 编译器。** Opus 4.6 Agent 团队在两周内以最少人工干预构建了 C 编译器。[查看详情 →](https://www.anthropic.com/engineering/building-c-compiler)

**Stability AI 发布新 7B LLM。** 开源，商业免费。1.9K❤️。

---

## 🎓 概念科普：混合专家模型（MoE）

Qwen 新的 397B 模型每次查询只激活 17B 参数——这就是**混合专家模型（MoE）**。模型不会运行所有 397B 参数，而是把每个输入路由到一小部分专业化的"专家"子网络。结果：你获得巨型模型的质量，但只花费小模型的速度和成本。这就是为什么模型在纸面上越来越"大"，但并没有等比例变慢。

---

## 🎯 今日精选：GGML 加入 Hugging Face

GGML 的创造者（让本地 LLM 推理成为可能的 llama.cpp 背后的引擎）加入 Hugging Face。这很重要，因为 llama.cpp 是几乎所有本地 AI 部署的骨干——从 Ollama 到 LM Studio 到无数应用。有了 HF 的资源支持，意味着更快的开发、更好的集成、以及在自己硬件上运行 AI 的更强未来。如果你关心本地 AI，这是本周最重要的新闻。[查看详情 →](https://huggingface.co/blog/ggml-joins-hf)
