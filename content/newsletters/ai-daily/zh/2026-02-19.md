# Sonnet 4.6 持续征服 Claude Code，巨型 MoE 模型争相开源

**2026 年 2 月 19 日**

Sonnet 4.6 在 Claude Code 中的表现持续让人刮目相看——越来越多的开发者在速度和能力的平衡上选择它而不是 Opus。开源方面，通义千问放出 397B MoE 巨兽，NVIDIA 的 PersonaPlex 走红。模型格局正在快速演变。

---

## 🧠 模型动态

**Sonnet 4.6 在 Claude Code 中大放异彩。** 比 Opus 4.6 便宜，接近 Opus 级别的智能。Boris Cherny（Claude Code 创作者）称其在 Cowork 模式下"能力、速度和 token 效率的绝佳平衡"。

**Gemini 3.1 Pro & Gemini 3 Deep Think。** Google DeepMind 推进前沿模型在复杂任务和科学发现方面的能力。

**GPT-5.2 & GPT-5.2-Codex 快了 40%。** OpenAI 优化推理基础设施，模型权重不变。

**Stability AI 发布新的开源 7B LLM。** 商业免费使用。

**HuggingFace 趋势：**
- GLM-5（1,388❤️，172K 下载）
- Qwen3.5-397B-A17B（731❤️）——巨型 MoE
- MiniMax-M2.5（789❤️，90K 下载）
- NVIDIA PersonaPlex 7B（2,060❤️）——音频到音频，持续走红

## 📱 产品应用

**Rork Max：一键生成 iPhone/Watch/iPad/Apple TV/Vision Pro 应用。** 号称"几乎可以一键生成任何应用"。大胆的宣言。

**Google Gemini 可以作曲了。** Gemini 应用的新创意能力。

**Project Genie。** Google DeepMind 实验性的无限交互式世界生成。

## 🔧 开发工具

**Anthropic API 自动缓存提示词。** 巨大的体验升级：不需要改任何代码，缓存自动生效。

**Claude Code + Figma 集成。** 通过更新的 Figma MCP 服务器，把 Claude Code 的输出直接推入 Figma。

**Cline CLI 2.0。** 开源终端 AI 编码 Agent。并行 Agent、无头模式。

**Letta Code。** 记忆优先的开源编码 Agent（Apache 2.0），模型无关。

**AWS 开源多 Agent AI 框架。** 实时路由、管理、编排多个 Agent。

**Bun：`bun build --compile --target=browser`。** 打包编译到浏览器目标（来自 Jarred Sumner）。

**OpenAI Skills + Hosted Shell。** Responses API 新增 Skills 支持和容器内网络 Shell。

**GPT Image 批量 API。** 图片模型支持批处理。

## 📝 技术洞察

**Anthropic 工程博客：基础设施噪声影响编码评测。** 基础设施配置可以让基准测试波动数个百分点，有时比顶级模型间差距还大。[查看详情 →](https://www.anthropic.com/engineering/infrastructure-noise)

**Anthropic 研究：衡量 AI Agent 在实践中的自主性。** 关于如何量化真实世界中 Agent 自主性的新研究。

**28 行代码写个 MCP 服务器。** Matt Pocock 的极简 MCP 服务器教程。兼容 Cursor、Windsurf、Claude Code、Zed。

**Claude Code 一周岁。** 现在贡献 4% 的全部 GitHub 提交，上月 DAU 翻倍。Spotify CEO 在财报电话会上背书。

**IBM & UC Berkeley：IT-Bench 和 MAST。** 诊断企业 Agent 为什么失败的框架。

## 🚀 前沿探索

**Google Jules。** Google 的编码 Agent，据说比 OpenAI Codex 更友好。

**Dreamer 发布。** 由 Instagram 联合创始人 Mike Krieger 背书。

**Better Agents。** 增强编码助手的开源项目。

**MCP 服务器目录。** 一个站点收录了 2,617 个 MCP 服务器。

---

## 🎓 概念科普：什么是基准测试中的"基础设施噪声"？

当我们在 SWE-bench 等编码基准测试上比较 AI 模型时，分数看起来很客观。但 Anthropic 的新研究表明，**基础设施配置**——超时设置、重试逻辑、容器规格、网络条件——可以让结果波动数个百分点。这通常**比排行榜上"第一名"和"第三名"之间的差距还大**。

意味着：不要对模型之间的小分差过度解读。2% 的差距可能只是测试配置的差异，不是实际模型能力。评估模型时，在你自己的环境中跑你自己的测试。

---

## 🎯 今日精选：Anthropic API 自动缓存提示词

Anthropic 悄悄上线了**自动提示词缓存**——无需修改任何代码。如果你在用相似的系统提示词或长上下文反复调用 API，你的成本刚刚降低了，延迟也改善了——一行代码都不用改。

这种基础设施层面的改进是会复利的：每个 API 用户都立即受益。如果你在用 Claude API 构建应用，去看看你的使用面板——你可能已经在省钱了。
