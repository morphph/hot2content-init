---
term: "微调（Fine-Tuning）"
slug: fine-tuning
lang: zh
category: LLM 基础
definition: "在特定数据集上进一步训练预训练语言模型的过程，以调整其行为、知识或风格来适应特定领域或任务。"
related: [prompt-engineering, rag-retrieval-augmented-generation]
date: 2026-02-10
source_topic: fine-tuning
---

## 什么是微调？

微调是将预训练基础模型（如 GPT 或 Claude）在专门数据集上进一步训练的过程。模型以其通用知识为起点，学习为特定领域、任务或风格调整输出。

打个比方：预训练模型是全科医生，微调把它变成心脏科专家——保留通用医学知识，但在专门领域更加精通。

## 工作原理

微调过程通常包括：

- **数据集准备**：整理高质量的输入-输出对，展示期望的行为
- **训练**：在数据集上运行额外的训练轮次，调整模型权重
- **评估**：用留出样本测试微调后的模型
- **部署**：将微调模型投入推理服务

常见方法包括：
- **全量微调**：更新所有模型参数（昂贵，质量最高）
- **LoRA（低秩适配）**：只更新小型适配层（更便宜，效果接近）
- **RLHF**：基于人类反馈的强化学习，用于对齐
- **DPO**：直接偏好优化，RLHF 的更简单替代

## 为什么重要

微调能实现仅靠提示无法达到的能力：

- **一致风格**：确保输出始终匹配品牌调性或技术标准
- **领域专精**：教会模型专业术语和推理模式
- **降低成本**：微调后的小模型在特定任务上可超越大型通用模型
- **降低延迟**：小型微调模型响应更快

然而在 2026 年，许多场景的趋势正从微调转向**提示 + RAG**。有了 100 万 token 上下文窗口，可以在提示中提供大量示例和文档，无需修改模型权重。微调仍然对以下场景不可或缺：需要大规模一致行为的生产系统、对延迟和单次请求成本敏感的任务、以及通过提示无法实现的能力。

## 相关术语

- **提示工程**：通过设计输入来定制模型行为，无需修改权重
- **RAG**：推理时用外部知识增强，与微调互补
- **迁移学习**：微调是其中一个具体实例的更广泛 ML 概念
