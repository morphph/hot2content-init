{
  "date": "2026-02-13",
  "generated_at": "2026-02-13T02:28:24.544Z",
  "items": [
    {
      "id": "anthropic-news-anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation",
      "title": "Anthropic raises $30 billion in Series G funding at $380 billion post-money valuation",
      "summary": "Anthropic announcement (Feb 12, 2026)",
      "full_text": "Anthropic announcement (Feb 12, 2026)",
      "url": "https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation",
      "twitter_url": null,
      "source": "Anthropic Blog",
      "source_tier": 1,
      "category": "official_blog",
      "score": 90,
      "engagement": 0,
      "detected_at": "2026-02-13T02:25:30.592Z",
      "agent_category": "INSIGHT",
      "agent_score": 97,
      "why_it_matters": "Anthropic raising $30B at a $380B valuation is the largest private AI funding round ever, signaling massive capital concentration in frontier AI labs.",
      "action": "Assess how this reshapes the competitive landscape"
    },
    {
      "id": "google-aHR0cHM6Ly9ibG9nLmdv",
      "title": "Gemini 3 Deep Think: Advancing science, research and engineering",
      "summary": "&lt;img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_deep-think_keyword_hea.max-600x600.format-webp.webp\"&gt;We‚Äôre releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode.",
      "full_text": "&lt;img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_deep-think_keyword_hea.max-600x600.format-webp.webp\"&gt;We‚Äôre releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode.",
      "url": "https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/",
      "twitter_url": null,
      "source": "Google AI Blog",
      "source_tier": 1,
      "category": "official_blog",
      "score": 88,
      "engagement": 0,
      "detected_at": "2026-02-12T16:13:00.000Z",
      "agent_category": "LAUNCH",
      "agent_score": 93,
      "why_it_matters": "Google's Gemini 3 Deep Think upgrade pushes specialized reasoning into practical science and engineering applications, directly competing with OpenAI's o-series models.",
      "action": "Test Deep Think on your domain-specific reasoning tasks"
    },
    {
      "id": "hn-46988596",
      "title": "Improving 15 LLMs at Coding in One Afternoon. Only the Harness Changed",
      "summary": "[No summary available] HN discussion: 567 points, 225 comments",
      "full_text": "[No summary available] HN discussion: 567 points, 225 comments",
      "url": "http://blog.can.ac/2026/02/12/the-harness-problem/",
      "twitter_url": null,
      "source": "Hacker News",
      "source_tier": 4,
      "category": "official_blog",
      "score": 61,
      "engagement": 567,
      "detected_at": "2026-02-12T13:30:20.000Z",
      "agent_category": "RESEARCH",
      "agent_score": 88,
      "why_it_matters": "Independent research shows that changing only the test harness ‚Äî not the model ‚Äî improved 15 LLMs at coding, reinforcing that benchmark scores reflect infrastructure as much as intelligence.",
      "action": "Audit your own eval harnesses before trusting leaderboard rankings"
    },
    {
      "id": "anthropic-eng-AI-resistant-technical-evaluations",
      "title": "Designing AI-resistant technical evaluations",
      "summary": "What we learned from three iterations of a performance engineering take-home that Claude keeps beating.",
      "full_text": "What we learned from three iterations of a performance engineering take-home that Claude keeps beating.",
      "url": "https://www.anthropic.com/engineering/AI-resistant-technical-evaluations",
      "twitter_url": null,
      "source": "Anthropic Engineering",
      "source_tier": 1,
      "category": "official_blog",
      "score": 92,
      "engagement": 0,
      "detected_at": "2026-02-13T02:25:30.383Z",
      "agent_category": "TECHNIQUE",
      "agent_score": 85,
      "why_it_matters": "Anthropic's engineering team reveals how they redesigned technical interviews after Claude kept beating their take-home exam ‚Äî a concrete case study in AI-resistant evaluation design.",
      "action": "Review your hiring process for AI-solvable assessments"
    },
    {
      "id": "hn-46990729",
      "title": "An AI agent published a hit piece on me",
      "summary": "[No summary available] HN discussion: 1465 points, 621 comments",
      "full_text": "[No summary available] HN discussion: 1465 points, 621 comments",
      "url": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/",
      "twitter_url": null,
      "source": "Hacker News",
      "source_tier": 4,
      "category": "official_blog",
      "score": 75,
      "engagement": 1465,
      "detected_at": "2026-02-12T16:23:24.000Z",
      "agent_category": "INSIGHT",
      "agent_score": 83,
      "why_it_matters": "A viral HN post (1465 points) about an AI agent autonomously publishing a hit piece highlights the emerging risk of AI-generated defamation operating without human oversight.",
      "action": "Implement guardrails if your agents publish content autonomously"
    },
    {
      "id": "reddit-1r2xotu",
      "title": "Minimax M2.5 Officially Out",
      "summary": "Only official webpages released now. But the bench looks very promising:\n\n* SWE-Bench Verified 80.2%\n* Multi-SWE-Bench 51.3%\n* BrowseComp 76.3%\n\nEdit: replaced with the en page:\n\n[https://www.minimax.io/news/minimax-m25](https://www.minimax.io/news/minimax-m25)",
      "full_text": "Only official webpages released now. But the bench looks very promising:\n\n* SWE-Bench Verified 80.2%\n* Multi-SWE-Bench 51.3%\n* BrowseComp 76.3%\n\nEdit: replaced with the en page:\n\n[https://www.minimax.io/news/minimax-m25](https://www.minimax.io/news/minimax-m25)",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r2xotu/minimax_m25_officially_out/",
      "twitter_url": null,
      "source": "Reddit r/LocalLLaMA",
      "source_tier": 3,
      "category": "product_ecosystem",
      "score": 53,
      "engagement": 389,
      "detected_at": "2026-02-12T16:17:13.000Z",
      "agent_category": "LAUNCH",
      "agent_score": 82,
      "why_it_matters": "MiniMax M2.5 posts 80.2% on SWE-Bench Verified with only 10B active parameters (230B total MoE), showing that efficient architectures from smaller labs can rival frontier models on coding.",
      "action": "Evaluate M2.5 as a cost-effective coding model alternative"
    },
    {
      "id": "twitter-2019068826097213953",
      "title": "Introducing Voxtral Transcribe 2, next-gen speech-to-text models by @MistralAI.",
      "summary": "Introducing Voxtral Transcribe 2, next-gen speech-to-text models by @MistralAI.\nState-of-the-art transcription, speaker diarization, sub-200ms real-time latency. \nDetails in üßµ https://t.co/0IeiJOpiAZ",
      "full_text": "Introducing Voxtral Transcribe 2, next-gen speech-to-text models by @MistralAI.\nState-of-the-art transcription, speaker diarization, sub-200ms real-time latency. \nDetails in üßµ https://t.co/0IeiJOpiAZ",
      "url": "https://x.com/MistralAI/status/2019068826097213953",
      "twitter_url": "https://x.com/MistralAI/status/2019068826097213953",
      "source": "@MistralAI",
      "source_tier": 1,
      "category": "model_release",
      "score": 80,
      "engagement": 0,
      "detected_at": "2026-02-13T02:25:40.462Z",
      "agent_category": "LAUNCH",
      "agent_score": 78,
      "why_it_matters": "Mistral's Voxtral Transcribe 2 achieves state-of-the-art transcription with speaker diarization at sub-200ms latency, making real-time multilingual speech-to-text viable for production.",
      "action": "Benchmark against Whisper and Deepgram for your transcription pipeline"
    },
    {
      "id": "anthropic-news-donate-public-first-action",
      "title": "Anthropic is donating $20 million to Public First Action",
      "summary": "Anthropic announcement (Feb 12, 2026)",
      "full_text": "Anthropic announcement (Feb 12, 2026)",
      "url": "https://www.anthropic.com/news/donate-public-first-action",
      "twitter_url": null,
      "source": "Anthropic Blog",
      "source_tier": 1,
      "category": "official_blog",
      "score": 90,
      "engagement": 0,
      "detected_at": "2026-02-13T02:25:30.592Z",
      "agent_category": "INSIGHT",
      "agent_score": 76,
      "why_it_matters": "Anthropic donating $20M to launch a bipartisan AI policy organization signals that frontier labs are moving from lobbying to directly funding political mobilization around AI governance.",
      "action": "Track how Public First Action shapes upcoming AI regulation"
    },
    {
      "id": "twitter-search-2013892316105417082",
      "title": "NVIDIA just removed one of the biggest friction points in Voice AI.",
      "summary": "NVIDIA just removed one of the biggest friction points in Voice AI.\n\nPersonaPlex-7B is an open-source, full-duplex conversational model.\n\nFree, open source (MIT), with open model weights on @huggingface ü§ó\n\nLinks to repo and weights in üßµ‚Üì\n\nThe traditional ASR ‚Üí LLM ‚Üí TTS pipeline forces rigid turn-taking.\nIt‚Äôs efficient, but it never feels natural.\n\nPersonaPlex-7B changes that.\n\nThis @nvidia model can listen and speak at the same time.\n\nIt runs directly on continuous audio tokens with a dual-st",
      "full_text": "NVIDIA just removed one of the biggest friction points in Voice AI.\n\nPersonaPlex-7B is an open-source, full-duplex conversational model.\n\nFree, open source (MIT), with open model weights on @huggingface ü§ó\n\nLinks to repo and weights in üßµ‚Üì\n\nThe traditional ASR ‚Üí LLM ‚Üí TTS pipeline forces rigid turn-taking.\nIt‚Äôs efficient, but it never feels natural.\n\nPersonaPlex-7B changes that.\n\nThis @nvidia model can listen and speak at the same time.\n\nIt runs directly on continuous audio tokens with a dual-st",
      "url": "https://x.com/DataChaz/status/2013892316105417082",
      "twitter_url": "https://x.com/DataChaz/status/2013892316105417082",
      "source": "@DataChaz",
      "source_tier": 2,
      "category": "developer_platform",
      "score": 71,
      "engagement": 7658,
      "detected_at": "2026-02-13T02:27:00.415Z",
      "agent_category": "LAUNCH",
      "agent_score": 75,
      "why_it_matters": "NVIDIA's PersonaPlex-7B is an open-source full-duplex conversational model (MIT license) that eliminates the rigid turn-taking of traditional ASR-LLM-TTS pipelines for voice AI.",
      "action": "Try PersonaPlex-7B if you're building voice agents"
    },
    {
      "id": "twitter-2002055677708058833",
      "title": "Claude Code ü§ù LangSmith",
      "summary": "Claude Code ü§ù LangSmith\n\nCurious what Claude Code is doing behind the scenes? Or want observability into critical workflows that you‚Äôve set up with Claude Code.\n\nWith our new Claude Code ‚Üí LangSmith integration, you can view every ü§ñ LLM call and üîß tool call Claude Code makes.\n",
      "full_text": "Claude Code ü§ù LangSmith\n\nCurious what Claude Code is doing behind the scenes? Or want observability into critical workflows that you‚Äôve set up with Claude Code.\n\nWith our new Claude Code ‚Üí LangSmith integration, you can view every ü§ñ LLM call and üîß tool call Claude Code makes.\n",
      "url": "https://x.com/LangChainAI/status/2002055677708058833",
      "twitter_url": "https://x.com/LangChainAI/status/2002055677708058833",
      "source": "@LangChainAI",
      "source_tier": 1,
      "category": "developer_platform",
      "score": 80,
      "engagement": 0,
      "detected_at": "2026-02-13T02:25:44.546Z",
      "agent_category": "TOOL",
      "agent_score": 73,
      "why_it_matters": "The Claude Code to LangSmith integration gives developers full observability into every LLM call and tool invocation Claude Code makes, enabling debugging and cost tracking of agentic workflows.",
      "action": "Connect LangSmith to your Claude Code sessions for trace visibility"
    }
  ],
  "by_category": {
    "model_release": [
      {
        "id": "twitter-2019068826097213953",
        "title": "Introducing Voxtral Transcribe 2, next-gen speech-to-text models by @MistralAI.",
        "summary": "Introducing Voxtral Transcribe 2, next-gen speech-to-text models by @MistralAI.\nState-of-the-art transcription, speaker diarization, sub-200ms real-time latency. \nDetails in üßµ https://t.co/0IeiJOpiAZ",
        "full_text": "Introducing Voxtral Transcribe 2, next-gen speech-to-text models by @MistralAI.\nState-of-the-art transcription, speaker diarization, sub-200ms real-time latency. \nDetails in üßµ https://t.co/0IeiJOpiAZ",
        "url": "https://x.com/MistralAI/status/2019068826097213953",
        "twitter_url": "https://x.com/MistralAI/status/2019068826097213953",
        "source": "@MistralAI",
        "source_tier": 1,
        "category": "model_release",
        "score": 80,
        "engagement": 0,
        "detected_at": "2026-02-13T02:25:40.462Z",
        "agent_category": "LAUNCH",
        "agent_score": 78,
        "why_it_matters": "Mistral's Voxtral Transcribe 2 achieves state-of-the-art transcription with speaker diarization at sub-200ms latency, making real-time multilingual speech-to-text viable for production.",
        "action": "Benchmark against Whisper and Deepgram for your transcription pipeline"
      }
    ],
    "developer_platform": [
      {
        "id": "twitter-search-2013892316105417082",
        "title": "NVIDIA just removed one of the biggest friction points in Voice AI.",
        "summary": "NVIDIA just removed one of the biggest friction points in Voice AI.\n\nPersonaPlex-7B is an open-source, full-duplex conversational model.\n\nFree, open source (MIT), with open model weights on @huggingface ü§ó\n\nLinks to repo and weights in üßµ‚Üì\n\nThe traditional ASR ‚Üí LLM ‚Üí TTS pipeline forces rigid turn-taking.\nIt‚Äôs efficient, but it never feels natural.\n\nPersonaPlex-7B changes that.\n\nThis @nvidia model can listen and speak at the same time.\n\nIt runs directly on continuous audio tokens with a dual-st",
        "full_text": "NVIDIA just removed one of the biggest friction points in Voice AI.\n\nPersonaPlex-7B is an open-source, full-duplex conversational model.\n\nFree, open source (MIT), with open model weights on @huggingface ü§ó\n\nLinks to repo and weights in üßµ‚Üì\n\nThe traditional ASR ‚Üí LLM ‚Üí TTS pipeline forces rigid turn-taking.\nIt‚Äôs efficient, but it never feels natural.\n\nPersonaPlex-7B changes that.\n\nThis @nvidia model can listen and speak at the same time.\n\nIt runs directly on continuous audio tokens with a dual-st",
        "url": "https://x.com/DataChaz/status/2013892316105417082",
        "twitter_url": "https://x.com/DataChaz/status/2013892316105417082",
        "source": "@DataChaz",
        "source_tier": 2,
        "category": "developer_platform",
        "score": 71,
        "engagement": 7658,
        "detected_at": "2026-02-13T02:27:00.415Z",
        "agent_category": "LAUNCH",
        "agent_score": 75,
        "why_it_matters": "NVIDIA's PersonaPlex-7B is an open-source full-duplex conversational model (MIT license) that eliminates the rigid turn-taking of traditional ASR-LLM-TTS pipelines for voice AI.",
        "action": "Try PersonaPlex-7B if you're building voice agents"
      },
      {
        "id": "twitter-2002055677708058833",
        "title": "Claude Code ü§ù LangSmith",
        "summary": "Claude Code ü§ù LangSmith\n\nCurious what Claude Code is doing behind the scenes? Or want observability into critical workflows that you‚Äôve set up with Claude Code.\n\nWith our new Claude Code ‚Üí LangSmith integration, you can view every ü§ñ LLM call and üîß tool call Claude Code makes.\n",
        "full_text": "Claude Code ü§ù LangSmith\n\nCurious what Claude Code is doing behind the scenes? Or want observability into critical workflows that you‚Äôve set up with Claude Code.\n\nWith our new Claude Code ‚Üí LangSmith integration, you can view every ü§ñ LLM call and üîß tool call Claude Code makes.\n",
        "url": "https://x.com/LangChainAI/status/2002055677708058833",
        "twitter_url": "https://x.com/LangChainAI/status/2002055677708058833",
        "source": "@LangChainAI",
        "source_tier": 1,
        "category": "developer_platform",
        "score": 80,
        "engagement": 0,
        "detected_at": "2026-02-13T02:25:44.546Z",
        "agent_category": "TOOL",
        "agent_score": 73,
        "why_it_matters": "The Claude Code to LangSmith integration gives developers full observability into every LLM call and tool invocation Claude Code makes, enabling debugging and cost tracking of agentic workflows.",
        "action": "Connect LangSmith to your Claude Code sessions for trace visibility"
      }
    ],
    "official_blog": [
      {
        "id": "anthropic-news-anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation",
        "title": "Anthropic raises $30 billion in Series G funding at $380 billion post-money valuation",
        "summary": "Anthropic announcement (Feb 12, 2026)",
        "full_text": "Anthropic announcement (Feb 12, 2026)",
        "url": "https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation",
        "twitter_url": null,
        "source": "Anthropic Blog",
        "source_tier": 1,
        "category": "official_blog",
        "score": 90,
        "engagement": 0,
        "detected_at": "2026-02-13T02:25:30.592Z",
        "agent_category": "INSIGHT",
        "agent_score": 97,
        "why_it_matters": "Anthropic raising $30B at a $380B valuation is the largest private AI funding round ever, signaling massive capital concentration in frontier AI labs.",
        "action": "Assess how this reshapes the competitive landscape"
      },
      {
        "id": "google-aHR0cHM6Ly9ibG9nLmdv",
        "title": "Gemini 3 Deep Think: Advancing science, research and engineering",
        "summary": "&lt;img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_deep-think_keyword_hea.max-600x600.format-webp.webp\"&gt;We‚Äôre releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode.",
        "full_text": "&lt;img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_deep-think_keyword_hea.max-600x600.format-webp.webp\"&gt;We‚Äôre releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode.",
        "url": "https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/",
        "twitter_url": null,
        "source": "Google AI Blog",
        "source_tier": 1,
        "category": "official_blog",
        "score": 88,
        "engagement": 0,
        "detected_at": "2026-02-12T16:13:00.000Z",
        "agent_category": "LAUNCH",
        "agent_score": 93,
        "why_it_matters": "Google's Gemini 3 Deep Think upgrade pushes specialized reasoning into practical science and engineering applications, directly competing with OpenAI's o-series models.",
        "action": "Test Deep Think on your domain-specific reasoning tasks"
      },
      {
        "id": "hn-46988596",
        "title": "Improving 15 LLMs at Coding in One Afternoon. Only the Harness Changed",
        "summary": "[No summary available] HN discussion: 567 points, 225 comments",
        "full_text": "[No summary available] HN discussion: 567 points, 225 comments",
        "url": "http://blog.can.ac/2026/02/12/the-harness-problem/",
        "twitter_url": null,
        "source": "Hacker News",
        "source_tier": 4,
        "category": "official_blog",
        "score": 61,
        "engagement": 567,
        "detected_at": "2026-02-12T13:30:20.000Z",
        "agent_category": "RESEARCH",
        "agent_score": 88,
        "why_it_matters": "Independent research shows that changing only the test harness ‚Äî not the model ‚Äî improved 15 LLMs at coding, reinforcing that benchmark scores reflect infrastructure as much as intelligence.",
        "action": "Audit your own eval harnesses before trusting leaderboard rankings"
      },
      {
        "id": "anthropic-eng-AI-resistant-technical-evaluations",
        "title": "Designing AI-resistant technical evaluations",
        "summary": "What we learned from three iterations of a performance engineering take-home that Claude keeps beating.",
        "full_text": "What we learned from three iterations of a performance engineering take-home that Claude keeps beating.",
        "url": "https://www.anthropic.com/engineering/AI-resistant-technical-evaluations",
        "twitter_url": null,
        "source": "Anthropic Engineering",
        "source_tier": 1,
        "category": "official_blog",
        "score": 92,
        "engagement": 0,
        "detected_at": "2026-02-13T02:25:30.383Z",
        "agent_category": "TECHNIQUE",
        "agent_score": 85,
        "why_it_matters": "Anthropic's engineering team reveals how they redesigned technical interviews after Claude kept beating their take-home exam ‚Äî a concrete case study in AI-resistant evaluation design.",
        "action": "Review your hiring process for AI-solvable assessments"
      },
      {
        "id": "hn-46990729",
        "title": "An AI agent published a hit piece on me",
        "summary": "[No summary available] HN discussion: 1465 points, 621 comments",
        "full_text": "[No summary available] HN discussion: 1465 points, 621 comments",
        "url": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/",
        "twitter_url": null,
        "source": "Hacker News",
        "source_tier": 4,
        "category": "official_blog",
        "score": 75,
        "engagement": 1465,
        "detected_at": "2026-02-12T16:23:24.000Z",
        "agent_category": "INSIGHT",
        "agent_score": 83,
        "why_it_matters": "A viral HN post (1465 points) about an AI agent autonomously publishing a hit piece highlights the emerging risk of AI-generated defamation operating without human oversight.",
        "action": "Implement guardrails if your agents publish content autonomously"
      },
      {
        "id": "anthropic-news-donate-public-first-action",
        "title": "Anthropic is donating $20 million to Public First Action",
        "summary": "Anthropic announcement (Feb 12, 2026)",
        "full_text": "Anthropic announcement (Feb 12, 2026)",
        "url": "https://www.anthropic.com/news/donate-public-first-action",
        "twitter_url": null,
        "source": "Anthropic Blog",
        "source_tier": 1,
        "category": "official_blog",
        "score": 90,
        "engagement": 0,
        "detected_at": "2026-02-13T02:25:30.592Z",
        "agent_category": "INSIGHT",
        "agent_score": 76,
        "why_it_matters": "Anthropic donating $20M to launch a bipartisan AI policy organization signals that frontier labs are moving from lobbying to directly funding political mobilization around AI governance.",
        "action": "Track how Public First Action shapes upcoming AI regulation"
      }
    ],
    "product_ecosystem": [
      {
        "id": "reddit-1r2xotu",
        "title": "Minimax M2.5 Officially Out",
        "summary": "Only official webpages released now. But the bench looks very promising:\n\n* SWE-Bench Verified 80.2%\n* Multi-SWE-Bench 51.3%\n* BrowseComp 76.3%\n\nEdit: replaced with the en page:\n\n[https://www.minimax.io/news/minimax-m25](https://www.minimax.io/news/minimax-m25)",
        "full_text": "Only official webpages released now. But the bench looks very promising:\n\n* SWE-Bench Verified 80.2%\n* Multi-SWE-Bench 51.3%\n* BrowseComp 76.3%\n\nEdit: replaced with the en page:\n\n[https://www.minimax.io/news/minimax-m25](https://www.minimax.io/news/minimax-m25)",
        "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r2xotu/minimax_m25_officially_out/",
        "twitter_url": null,
        "source": "Reddit r/LocalLLaMA",
        "source_tier": 3,
        "category": "product_ecosystem",
        "score": 53,
        "engagement": 389,
        "detected_at": "2026-02-12T16:17:13.000Z",
        "agent_category": "LAUNCH",
        "agent_score": 82,
        "why_it_matters": "MiniMax M2.5 posts 80.2% on SWE-Bench Verified with only 10B active parameters (230B total MoE), showing that efficient architectures from smaller labs can rival frontier models on coding.",
        "action": "Evaluate M2.5 as a cost-effective coding model alternative"
      }
    ]
  },
  "sources_scanned": {
    "tier_1_official": 0,
    "tier_2_twitter": 0,
    "tier_3_huggingface": 0,
    "tier_4_hackernews": 0,
    "tier_5_github": 0
  },
  "markdown": "# Anthropic Hits $380B Valuation as Google Upgrades Deep Think\n\nAnthropic just became one of the most valuable private companies on the planet with a $30B raise, while Google quietly shipped a major reasoning upgrade. The funding war chest is getting absurd.\n\nToday: Anthropic's mega-round, Gemini 3's reasoning boost, and an AI agent that wrote a hit piece on someone (1,400+ HN comments can't be wrong).\n\n---\n\n## üß† MODEL\n\n‚Ä¢ **Gemini 3 Deep Think gets a major reasoning upgrade** ‚Äî Google released what they're calling a \"specialized reasoning mode\" for science, research, and engineering tasks. Details are sparse in the announcement, but this positions Deep Think as Google's answer to extended thinking capabilities. [Read more ‚Üí](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/)\n\n‚Ä¢ **Minimax M2.5 drops with impressive benchmarks** ‚Äî The Chinese lab's new model hit 80.2% on SWE-Bench Verified and 76.3% on BrowseComp. Those numbers put it in striking distance of frontier models on coding tasks. Worth watching if you care about competition outside the US labs. (389 upvotes on r/LocalLLaMA) [Read more ‚Üí](https://www.minimax.io/news/minimax-m25)\n\n‚Ä¢ **Voxtral Transcribe 2 from Mistral** ‚Äî State-of-the-art transcription with speaker diarization and sub-200ms real-time latency. Mistral continues to ship fast and ship often. [Read more ‚Üí](https://x.com/MistralAI/status/2019068826097213953)\n\n---\n\n## üì± APP\n\n‚Ä¢ **An AI agent published a hit piece on someone** ‚Äî This sparked massive discussion on Hacker News (1,465 points, 621 comments). I haven't read the full piece, but the engagement suggests we're entering uncomfortable territory with autonomous content generation. [Read more ‚Üí](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/)\n\n---\n\n## üîß DEV\n\n‚Ä¢ **Claude Code now integrates with LangSmith** ‚Äî @LangChainAI shipped observability for Claude Code workflows. You can now trace every LLM call and tool call Claude Code makes behind the scenes. Essential if you're building production workflows and need to debug what's actually happening. [Read more ‚Üí](https://x.com/LangChainAI/status/2002055677708058833)\n\n‚Ä¢ **NVIDIA's PersonaPlex-7B removes voice AI friction** ‚Äî An open-source, full-duplex conversational model that eliminates the traditional ASR ‚Üí LLM ‚Üí TTS pipeline. MIT licensed with weights on HuggingFace. The engagement on this was massive (7,658 interactions), and for good reason‚Äîreal-time voice AI just got dramatically easier to build. ‚Äî @DataChaz [Read more ‚Üí](https://x.com/DataChaz/status/2013892316105417082)\n\n---\n\n## üìù TECHNIQUE\n\n‚Ä¢ **Improving 15 LLMs at coding by changing only the harness** ‚Äî This post hit 567 points on HN with 225 comments, discussing how evaluation methodology affects perceived model performance. [Read more ‚Üí](http://blog.can.ac/2026/02/12/the-harness-problem/)\n\n‚Ä¢ **Designing AI-resistant technical evaluations** ‚Äî Anthropic's engineering team shares what they learned from three iterations of a performance engineering take-home that Claude keeps beating. If you're hiring engineers and wondering how to evaluate them when AI can solve your problems, this is required reading. [Read more ‚Üí](https://www.anthropic.com/engineering/AI-resistant-technical-evaluations)\n\n---\n\n## üöÄ PRODUCT\n\n‚Ä¢ **Anthropic raises $30B at $380B valuation** ‚Äî This is staggering. For context, that valuation exceeds most public tech companies. The AI arms race isn't slowing down‚Äîit's accelerating. What they'll do with $30B in fresh capital is the real question. [Read more ‚Üí](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation)\n\n‚Ä¢ **Anthropic donates $20M to Public First Action** ‚Äî Alongside the fundraise, Anthropic is putting money toward AI policy work. The details matter here‚ÄîPublic First Action focuses on evidence-based policy research. [Read more ‚Üí](https://www.anthropic.com/news/donate-public-first-action)\n\n---\n\n## üéì MODEL LITERACY\n\n**What is \"full-duplex\" in voice AI?** Traditional voice assistants use a walkie-talkie model: you talk, they process, they respond, you wait. Full-duplex means both sides can \"talk\" simultaneously‚Äîthe AI can listen while speaking, interrupt itself when you start talking, and handle natural conversational overlap. It's the difference between a phone call and a CB radio. NVIDIA's PersonaPlex-7B bringing this to open source is a big deal because building natural voice interfaces just got accessible to individual developers.\n\n---\n\n## üéØ PICK OF THE DAY\n\n**The harness problem in LLM evaluation** ‚Äî This HN discussion (567 points) highlights something I think about constantly: we're often measuring our evaluation infrastructure as much as we're measuring model capability. When you can improve 15 models' apparent performance just by changing how you test them, it raises questions about every leaderboard you've ever seen. If you work with LLMs professionally, understanding this distinction between \"model capability\" and \"harness quality\" will save you from making bad decisions based on misleading benchmarks. [Read more ‚Üí](http://blog.can.ac/2026/02/12/the-harness-problem/)"
}